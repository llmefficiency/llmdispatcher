# LLM Dispatcher API Keys Configuration
# Copy this file to .env and fill in your actual API keys

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_TIMEOUT=30s

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_TIMEOUT=30s

# Google Configuration
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com
GOOGLE_TIMEOUT=30s

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_TIMEOUT=30s

# Cohere Configuration
COHERE_API_KEY=your-cohere-api-key-here
COHERE_BASE_URL=https://api.cohere.ai
COHERE_TIMEOUT=30s

# Optional: Rate limiting configuration
OPENAI_RATE_LIMIT_REQUESTS_PER_MINUTE=60
OPENAI_RATE_LIMIT_TOKENS_PER_MINUTE=90000
ANTHROPIC_RATE_LIMIT_REQUESTS_PER_MINUTE=50
ANTHROPIC_RATE_LIMIT_TOKENS_PER_MINUTE=40000 